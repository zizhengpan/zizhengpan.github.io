---
permalink: /
title: ""
excerpt: ""
author_profile: true
---
# About Me

Hi üëã, I am a final-year PhD student at Monash University, supervised by [Asst. Prof. Bohan Zhuang](https://scholar.google.com.au/citations?user=DFuDBBwAAAAJ) and [Prof. Jianfei Cai](https://scholar.google.com.au/citations?user=N6czCoUAAAAJ). I am a member of [ZIP Lab](https://ziplab.github.io/). Previously I was a Master student at the University of Adelaide. Prior to that, I received my bachelors' degree from Harbin Institute of Technology, Weihai, a beautiful coastal campus üèñÔ∏è, which left me with cherished memories. Here is my [CV](https://zizhengpan.github.io/files/cv_zizheng.pdf).

My research is all about **efficency** in deep neural networks, including training, inference, and deployment. Some topics that I currently focus on:
- Flexible model deployment: [SN-Net](https://arxiv.org/abs/2302.06586), [SN-Netv2](https://arxiv.org/abs/2307.00154)
- Transformer architcture optimization: [LIT](https://arxiv.org/abs/2105.14217), [LITv2](https://arxiv.org/abs/2205.13213)
- Efficient attention mechansims: [HiLo](https://arxiv.org/abs/2205.13213), [EcoFormer](https://arxiv.org/abs/2209.09004)
- Token pruning/merging for inference speedup: [HVT](https://arxiv.org/abs/2103.10619)
- Memory-efficient training: [Mesa](https://github.com/ziplab/Mesa)





## News
- **2023.12.29** &emsp; One paper is accepted by TPAMI!
- **2023.10.25** &emsp; I gave an online talk at University of Massachusetts Amherst.
- **2023.04.20** &emsp; One paper is accepted by IJCAI 2023!
- **2023.04.11** &emsp; I will be interning at NVIDIA Research this summer.
- **2023.03.22** &emsp; SN-Net was selected as a highlight at CVPR 2023!üî•
- **2023.02.28** &emsp; Two papers are accepted by CVPR 2023!
- **2022.11.11** &emsp; Both LITv2 and Ecoformer will be presented as Spotlight!
- **2022.09.15** &emsp; Our [LITv2](https://arxiv.org/abs/2205.13213) and [EcoFormer](https://github.com/ziplab/EcoFormer) are accepted by NeurIPS 2022.
- **2022.07.04** &emsp; Our paper [STPT](https://arxiv.org/abs/2207.10448) is accepted by ECCV 2022.
- **2021.12.01** &emsp; Our paper [LIT](https://arxiv.org/abs/2105.14217) is accepted by AAAI 2022.
- **2021.07.23** &emsp; Our paper [HVT](https://arxiv.org/abs/2103.10619) and [ORIST](https://arxiv.org/abs/2104.04167) are accepted by ICCV 2021.



## Education

- Ph.D in Computer Science, Monash University, 2021 - Now.
- M.S. in Computer Science, The University of Adelaide, 2020.
- B.E. in Software Engineering, Harbin Institute of Technology, Weihai, 2019.



## Work Experience

- Intern, NVIDIA, AI Algorithm Group, July, 2023 - Oct, 2023



## Research

<dl>
  <dt ><img align="left" width="170" hspace="10"  wspace="20" src="../images/t_stitch.jpg"></dt>
  <dt> T-Stitch: Accelerating Sampling in Pre-trained Diffusion Models with Trajectory Stitching</dt>
  <dd><strong>Zizheng Pan</strong>, Bohan Zhuang, De-An Huang, Weili Nie, Zhiding Yu, Chaowei Xiao, Jianfei Cai, Anima Anandkumar</dd>
  <dd> ArXiv, 2024.</dd>
  <dd> 
    <a href="https://arxiv.org/abs/2402.14167">[Paper]</a>
    <a href="https://github.com/NVlabs/T-Stitch">[Code]</a> 
    <a href="https://t-stitch.github.io/">[Project Page]</a> 
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10"  wspace="20" src="../images/snnetv2.jpg"></dt>
  <dt> Stitched ViTs are Flexible Vision Backbones</dt>
  <dd><strong>Zizheng Pan</strong>, Jing Liu, Haoyu He, Jianfei Cai, Bohan Zhuang</dd>
  <dd> ArXiv, 2023.</dd>
  <dd> 
    <a href="https://arxiv.org/abs/2307.00154">[Paper]</a>
    <a href="https://github.com/ziplab/SN-Netv2">[Code]</a> 
    <a href="https://snnet.github.io/snnetv2/">[Project Page]</a> 
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10"  wspace="20" src="../images/esta.jpg"></dt>
  <dt> Efficient Stitchable Task Adaptation</dt>
  <dd>Haoyu He, <strong>Zizheng Pan</strong>, Jing Liu, Jianfei Cai, Bohan Zhuang</dd>
  <dd> ArXiv, 2023.</dd>
  <dd> 
    <a href="https://arxiv.org/abs/2311.17352">[Paper]</a>
    <a href="https://github.com/ziplab/Stitched_LLaMA">[Code]</a> 
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/spvit.png"></dt>
  <dt> Pruning Self-attentions into Convolutional Layers in Single Path</dt>
  <dd>Haoyu He, Jing Liu, <strong>Zizheng Pan</strong>, Jianfei Cai, Jing Zhang, Dacheng Tao, Bohan Zhuang</dd>
  <dd>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2023.</dd>
  <dd>
    <a href="https://github.com/ziplab/SPViT">[Code]</a>, 
    <a href="https://arxiv.org/abs/2111.11802">[Paper]</a>
  </dd>
</dl>


---

<dl>
  <dt ><img align="left" width="170" hspace="10"  wspace="20" src="../images/eff_train_transformer.jpg"></dt>
  <dt> A Survey on Efficient Training of Transformers</dt>
  <dd>Bohan Zhuang, Jing Liu, <strong>Zizheng Pan</strong>, Haoyu He, Yuetian Weng, Chunhua Shen</dd>
  <dd> International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2023.</dd>
  <dd> 
    <a href="https://arxiv.org/abs/2302.01107">[Paper]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10"  wspace="20" src="../images/snnet.jpg"></dt>
  <dt> Stitchable Neural Networks</dt>
  <dd><strong>Zizheng Pan</strong>, Jianfei Cai, Bohan Zhuang</dd>
  <dd> Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023 <font color="#c91f37">(Highlight)</font></dd>
  <dd>
    <a href="https://github.com/ziplab/SN-Net">[Code]</a>, 
    <a href="https://arxiv.org/abs/2302.06586">[Paper]</a>,
    <a href="https://snnet.github.io/">[Project Page]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10"  wspace="20" src="../images/faseg.jpg"></dt>
  <dt> Dynamic Focus-aware Positional Queries for Semantic Segmentation</dt>
  <dd> Haoyu He, Jianfei Cai, <strong>Zizheng Pan</strong>, Jing liu, Jing Zhang, Dacheng Tao and Bohan Zhuang.</dd>
  <dd> Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</dd>
  <dd>
    <a href="https://github.com/ziplab/FASeg">[Code]</a>, 
    <a href="https://arxiv.org/abs/2204.01244">[Paper]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10"  wspace="20" src="../images/litv2.jpg"></dt>
  <dt> Fast Vision Transformers with HiLo Attention</dt>
  <dd><strong>Zizheng Pan</strong>, Jianfei Cai, Bohan Zhuang</dd>
  <dd> Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022 <font color="#c91f37">(Spotlight)</font></dd>
  <dd>
    <a href="https://github.com/ziplab/LITv2">[Code]</a>, 
    <a href="https://arxiv.org/abs/2205.13213">[Paper]</a>,
    <a href="https://openreview.net/forum?id=Pyd6Rh9r1OT">[OpenReview]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/ecoformer.jpg"></dt>
  <dt> EcoFormer: Energy-Saving Attention with Linear Complexity</dt>
  <dd>Jing Liu*, <strong>Zizheng Pan*</strong>, Haoyu He, Jianfei Cai, Bohan Zhuang (*equal contribution)</dd>
  <dd> Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022  <font color="#c91f37">(Spotlight)</font></dd>
  <dd>
    <a href="https://github.com/ziplab/EcoFormer">[Code]</a>, 
    <a href="https://arxiv.org/abs/2209.09004">[Paper]</a>,
    <a href="https://openreview.net/forum?id=MK_130d4Y0">[OpenReview]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/stpt.jpg"></dt>
  <dt> An Efficient Spatio-Temporal Pyramid Transformer for Action Detection</dt>
  <dd>Yuetian Weng, <strong>Zizheng Pan</strong>, Mingfei Han, Xiaojun Chang, Bohan Zhuang</dd>
  <dd>European Conference on Computer Vision (<strong>ECCV</strong>), 2022</dd>
  <dd>
    <a href="https://github.com/ziplab/STPT">[Code]</a>, 
    <a href="https://arxiv.org/abs/2207.10448">[Paper]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/mesa.png"></dt>
  <dt> Mesa: A Memory-saving Training Framework for Transformers</dt>
  <dd><strong>Zizheng Pan</strong>, Peng Chen, Haoyu He, Jing Liu, Jianfei Cai, Bohan Zhuang</dd>
  <dd>Arxiv, 2021</dd>
  <dd>
    <a href="https://github.com/ziplab/Mesa">[Code]</a>, 
    <a href="https://arxiv.org/abs/2111.11124">[Paper]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/lit.jpg"></dt>
  <dt> Less is More: Pay Less Attention in Vision Transformers</dt>
  <dd><strong>Zizheng Pan</strong>, Bohan Zhuang, Haoyu He, Jing Liu, Jianfei Cai</dd>
  <dd>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2022</dd>
  <dd>
    <a href="https://github.com/ziplab/LIT">[Code]</a>, 
    <a href="https://arxiv.org/abs/2105.14217">[Paper]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/hvt.jpg"></dt>
  <dt> Scalable Visual Transformers with Hierarchical Pooling</dt>
  <dd><strong>Zizheng Pan</strong>, Bohan Zhuang, Jing Liu, Haoyu He, Jianfei Cai</dd>
  <dd>International Conference on Computer Vision (<strong>ICCV</strong>), 2021</dd>
  <dd>
  	<a href="https://github.com/ziplab/HVT">[Code]</a>,
    <a href="https://arxiv.org/abs/2103.10619">[Paper]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/orist.jpg"></dt>
  <dt> The Road to Know-Where: An Object-and-Room Informed Sequential BERT for Indoor Vision-Language Navigation</dt>
  <dd>Yuankai Qi, <strong>Zizheng Pan</strong>, Yicong Hong, Ming-Hsuan Yang, Anton van den Hengel, Qi Wu</dd>
  <dd>International Conference on Computer Vision (<strong>ICCV</strong>), 2021</dd>
  <dd>
    <a href="https://github.com/YuankaiQi/ORIST">[Code]</a>,
    <a href="https://arxiv.org/abs/2104.04167">[Paper]</a>
  </dd>
</dl>

---

<dl>
  <dt ><img align="left" width="170" hspace="10" src="../images/oaa.jpg"></dt>
  <dt> Object-and-Action Aware Model for Visual Language Navigation</dt>
  <dd>Yuankai Qi, <strong>Zizheng Pan</strong>, Shengping Zhang, Anton van den Hengel, Qi Wu</dd>
  <dd>European Conference on Computer Vision (<strong>ECCV</strong>), 2020</dd>
  <dd>
    <a href="https://arxiv.org/abs/2007.14626">[Paper]</a>
  </dd>
</dl>


## Teaching

- FIT5201 - Machine learning, 2022, TA

## Talk

- 2023.10.25  &emsp;  "Optimizing Vision Transformers for Efficient Training, Inference and Deployment", invited online talk at University of Massachusetts Amherst.


## Professional Activities

Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, IJCV


## Awards

- Google Travel and Conference Grants, 2023
- Monash Graduate Scholarship, 2020
- Adelaide Summer Research Scholarship, 2019
- Outstanding Graduate in Harbin Institute of Technology, 2019
